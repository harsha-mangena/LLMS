{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1281b68-a8d7-45c9-9ebc-ed85505061ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U transformers datasets accelerate peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e426a5-12a7-4cbe-b9f3-44ae7d5f7d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/bitsandbytes/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "print(bnb.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d90854b7-0dbe-43d8-9603-460eba692962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f7a50c8-1e6d-4b29-b8e9-fbe89ce8dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_datasets(tokenizer, max_length=512, dataset_sample=None):\n",
    "    \"\"\"\n",
    "    Load Spider and WikiSQL datasets, tokenize them, and optionally sample.\n",
    "    \"\"\"\n",
    "    spider_dataset = load_dataset(\"spider\", split=\"train\")\n",
    "    wikisql_dataset = load_dataset(\"wikisql\", split=\"train\")\n",
    "    \n",
    "    if dataset_sample:\n",
    "        spider_dataset = spider_dataset.select(range(min(dataset_sample, len(spider_dataset))))\n",
    "        wikisql_dataset = wikisql_dataset.select(range(min(dataset_sample, len(wikisql_dataset))))\n",
    "    \n",
    "    combined_dataset = concatenate_datasets([spider_dataset, wikisql_dataset])\n",
    "    \n",
    "    def preprocess_function(examples):\n",
    "        questions = examples.get(\"question\", [])\n",
    "        if not questions:\n",
    "            questions = [\"\"] * len(examples[list(examples.keys())[0]])\n",
    "        \n",
    "        targets = []\n",
    "        if \"query\" in examples:\n",
    "            targets = examples[\"query\"]\n",
    "        elif \"sql\" in examples:\n",
    "            sql_field = examples[\"sql\"]\n",
    "            if isinstance(sql_field, list) and len(sql_field) > 0 and isinstance(sql_field[0], dict):\n",
    "                targets = [str(d.get(\"human_readable\", \"\")) for d in sql_field]\n",
    "            else:\n",
    "                targets = [\"\"] * len(questions)\n",
    "        else:\n",
    "            targets = [\"\"] * len(questions)\n",
    "        \n",
    "        # Ensure all inputs are strings\n",
    "        inputs = [str(q) if q is not None else \"\" for q in questions]\n",
    "        targets = [str(t) if t is not None else \"\" for t in targets]\n",
    "        \n",
    "        model_inputs = tokenizer(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "        \n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(\n",
    "                targets,\n",
    "                max_length=max_length,\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "        \n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "    \n",
    "    tokenized_dataset = combined_dataset.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=combined_dataset.column_names,\n",
    "    )\n",
    "    \n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbf37ce5-b730-44b3-b03a-c225bd73f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qlora_model(\n",
    "    base_model_name=\"salesforce/CodeGen2-7B\",\n",
    "    hf_token=None,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load the 'salesforce/CodeGen2-7B' model in 4-bit with BitsAndBytesConfig,\n",
    "    then apply a LoRA adapter.\n",
    "    \"\"\"\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        base_model_name,\n",
    "        use_auth_token=hf_token,\n",
    "        use_fast=True,\n",
    "    )\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        device_map=device_map,\n",
    "        torch_dtype=torch_dtype,\n",
    "        use_auth_token=hf_token,\n",
    "        quantization_config=bnb_config,\n",
    "    )\n",
    "\n",
    "    target_modules = [\n",
    "        \"attn.q_proj\",\n",
    "        \"attn.k_proj\",\n",
    "        \"attn.v_proj\",\n",
    "        \"attn.out_proj\",\n",
    "    ]\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        r=r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        target_modules=target_modules,\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    peft_model = get_peft_model(base_model, peft_config)\n",
    "    return tokenizer, peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d782daff-46c6-4853-85ba-b6ccd260eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_qlora(\n",
    "    tokenizer,\n",
    "    model,\n",
    "    tokenized_dataset,\n",
    "    output_dir=\"./qlora-text-to-sql\",\n",
    "    num_epochs=3,\n",
    "    batch_size=4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fine-tune QLoRA model on the combined Spider + WikiSQL dataset.\n",
    "    Saves the final model locally to <output_dir>-final.\n",
    "    \"\"\"\n",
    "    split_dataset = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "    train_dataset = split_dataset[\"train\"]\n",
    "    eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=True,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=1,\n",
    "        num_train_epochs=num_epochs,\n",
    "        logging_steps=100,\n",
    "        save_steps=500,\n",
    "        fp16=True,\n",
    "        report_to=\"none\",  \n",
    "    )\n",
    "\n",
    "    # Create the Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "    )\n",
    "\n",
    "    print(\"\\nStarting fine-tuning... Please wait.\\n\")\n",
    "    trainer.train()\n",
    "    print(\"\\nTraining is complete!\\n\")\n",
    "\n",
    "    trainer.save_model(f\"{output_dir}-final\")\n",
    "    tokenizer.save_pretrained(f\"{output_dir}-final\")\n",
    "\n",
    "    print(f\"\\nModel and tokenizer saved at '{output_dir}-final'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "940f225c-e44b-4070-b33a-be72ba6cdca2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:05<00:00,  1.84s/it]\n",
      "Some weights of the model checkpoint at salesforce/CodeGen2-7B were not used when initializing CodeGenForCausalLM: ['transformer.h.0.attn.causal_mask', 'transformer.h.1.attn.causal_mask', 'transformer.h.10.attn.causal_mask', 'transformer.h.11.attn.causal_mask', 'transformer.h.12.attn.causal_mask', 'transformer.h.13.attn.causal_mask', 'transformer.h.14.attn.causal_mask', 'transformer.h.15.attn.causal_mask', 'transformer.h.16.attn.causal_mask', 'transformer.h.17.attn.causal_mask', 'transformer.h.18.attn.causal_mask', 'transformer.h.19.attn.causal_mask', 'transformer.h.2.attn.causal_mask', 'transformer.h.20.attn.causal_mask', 'transformer.h.21.attn.causal_mask', 'transformer.h.22.attn.causal_mask', 'transformer.h.23.attn.causal_mask', 'transformer.h.24.attn.causal_mask', 'transformer.h.25.attn.causal_mask', 'transformer.h.26.attn.causal_mask', 'transformer.h.27.attn.causal_mask', 'transformer.h.28.attn.causal_mask', 'transformer.h.29.attn.causal_mask', 'transformer.h.3.attn.causal_mask', 'transformer.h.30.attn.causal_mask', 'transformer.h.31.attn.causal_mask', 'transformer.h.4.attn.causal_mask', 'transformer.h.5.attn.causal_mask', 'transformer.h.6.attn.causal_mask', 'transformer.h.7.attn.causal_mask', 'transformer.h.8.attn.causal_mask', 'transformer.h.9.attn.causal_mask']\n",
      "- This IS expected if you are initializing CodeGenForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CodeGenForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63355/63355 [00:17<00:00, 3696.29 examples/s]\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning... Please wait.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42765' max='42765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42765/42765 8:44:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.040905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.038530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.037256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: fda3c2da-450d-4e2c-965a-29a2b17bfc00)') - silently ignoring the lookup for the file config.json in salesforce/CodeGen2-7B.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in salesforce/CodeGen2-7B - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 3a40b662-3659-4f35-a218-08bb19d879c9)') - silently ignoring the lookup for the file config.json in salesforce/CodeGen2-7B.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in salesforce/CodeGen2-7B - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f2ac5244-6f63-463f-8ee9-c280cd304679)') - silently ignoring the lookup for the file config.json in salesforce/CodeGen2-7B.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in salesforce/CodeGen2-7B - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: e9686184-ad7d-49c4-99d6-f9ef2f99e2d7)') - silently ignoring the lookup for the file config.json in salesforce/CodeGen2-7B.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in salesforce/CodeGen2-7B - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 2a311abb-defd-4156-a147-828634dba30c)') - silently ignoring the lookup for the file config.json in salesforce/CodeGen2-7B.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in salesforce/CodeGen2-7B - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 51ef9ace-9273-4cc4-9826-4e57ffcc248b)') - silently ignoring the lookup for the file config.json in salesforce/CodeGen2-7B.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in salesforce/CodeGen2-7B - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 853f04b5-012a-449f-b5e9-232e2fdaf301)') - silently ignoring the lookup for the file config.json in salesforce/CodeGen2-7B.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in salesforce/CodeGen2-7B - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training is complete! Now saving the model locally...\n",
      "\n",
      "\n",
      "Model and tokenizer saved at './qlora-text-to-sql-final'.\n",
      "If you're on a local machine, you'll find them in that folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 33d435ba-d8cc-4177-9d44-b71947f0ef9f)') - silently ignoring the lookup for the file config.json in salesforce/CodeGen2-7B.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in salesforce/CodeGen2-7B - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "base_model_name = \"salesforce/CodeGen2-7B\"\n",
    "hf_token = None\n",
    "\n",
    "tokenizer, peft_model = create_qlora_model(\n",
    "    base_model_name=base_model_name,\n",
    "    hf_token=hf_token,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "tokenized_dataset = load_and_prepare_datasets(tokenizer, max_length=512)\n",
    "\n",
    "fine_tune_qlora(\n",
    "    tokenizer,\n",
    "    peft_model,\n",
    "    tokenized_dataset,\n",
    "    output_dir=\"./qlora-text-to-sql\",\n",
    "    num_epochs=3,\n",
    "    batch_size=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9606c962-471f-4ed7-846d-a84b044c1386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.66s/it]\n",
      "Some weights of the model checkpoint at salesforce/CodeGen2-7B were not used when initializing CodeGenForCausalLM: ['transformer.h.0.attn.causal_mask', 'transformer.h.1.attn.causal_mask', 'transformer.h.10.attn.causal_mask', 'transformer.h.11.attn.causal_mask', 'transformer.h.12.attn.causal_mask', 'transformer.h.13.attn.causal_mask', 'transformer.h.14.attn.causal_mask', 'transformer.h.15.attn.causal_mask', 'transformer.h.16.attn.causal_mask', 'transformer.h.17.attn.causal_mask', 'transformer.h.18.attn.causal_mask', 'transformer.h.19.attn.causal_mask', 'transformer.h.2.attn.causal_mask', 'transformer.h.20.attn.causal_mask', 'transformer.h.21.attn.causal_mask', 'transformer.h.22.attn.causal_mask', 'transformer.h.23.attn.causal_mask', 'transformer.h.24.attn.causal_mask', 'transformer.h.25.attn.causal_mask', 'transformer.h.26.attn.causal_mask', 'transformer.h.27.attn.causal_mask', 'transformer.h.28.attn.causal_mask', 'transformer.h.29.attn.causal_mask', 'transformer.h.3.attn.causal_mask', 'transformer.h.30.attn.causal_mask', 'transformer.h.31.attn.causal_mask', 'transformer.h.4.attn.causal_mask', 'transformer.h.5.attn.causal_mask', 'transformer.h.6.attn.causal_mask', 'transformer.h.7.attn.causal_mask', 'transformer.h.8.attn.causal_mask', 'transformer.h.9.attn.causal_mask']\n",
      "- This IS expected if you are initializing CodeGenForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CodeGenForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CodeGenForCausalLM(\n",
       "  (transformer): CodeGenModel(\n",
       "    (wte): Embedding(51200, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x CodeGenBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "model_path = \"./qlora-text-to-sql-final\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    use_fast=True,\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\",\n",
    ")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed41ef7a-3ee4-4288-8443-1f668d5e95dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql(question, max_new_tokens=128):\n",
    "    \"\"\"\n",
    "    Given a question in English, return the model's SQL generation as a string.\n",
    "    \"\"\"\n",
    "    # Construct the prompt ( add special instructions or schema info).\n",
    "    # For example:\n",
    "    prompt = f\"Question: {question}\\nGenerate the SQL query:\\n\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,  \n",
    "            top_p=0.9,         \n",
    "            temperature=0.8,     \n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "549f3f9c-30e1-4ec4-9ae0-ac112d965395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL:\n",
      " Question: List the name and age of all students older than 20.\n",
      "Generate the SQL query:\n",
      "SELECT student_name , age FROM student WHERE age >= 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_question = \"List the name and age of all students older than 20.\"\n",
    "generated_sql = generate_sql(sample_question)\n",
    "print(\"Generated SQL:\\n\", generated_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71f1c883-2b48-4749-85b0-c62d1bcd2b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.63it/s]\n",
      "Some weights of the model checkpoint at salesforce/CodeGen2-7B were not used when initializing CodeGenForCausalLM: ['transformer.h.0.attn.causal_mask', 'transformer.h.1.attn.causal_mask', 'transformer.h.10.attn.causal_mask', 'transformer.h.11.attn.causal_mask', 'transformer.h.12.attn.causal_mask', 'transformer.h.13.attn.causal_mask', 'transformer.h.14.attn.causal_mask', 'transformer.h.15.attn.causal_mask', 'transformer.h.16.attn.causal_mask', 'transformer.h.17.attn.causal_mask', 'transformer.h.18.attn.causal_mask', 'transformer.h.19.attn.causal_mask', 'transformer.h.2.attn.causal_mask', 'transformer.h.20.attn.causal_mask', 'transformer.h.21.attn.causal_mask', 'transformer.h.22.attn.causal_mask', 'transformer.h.23.attn.causal_mask', 'transformer.h.24.attn.causal_mask', 'transformer.h.25.attn.causal_mask', 'transformer.h.26.attn.causal_mask', 'transformer.h.27.attn.causal_mask', 'transformer.h.28.attn.causal_mask', 'transformer.h.29.attn.causal_mask', 'transformer.h.3.attn.causal_mask', 'transformer.h.30.attn.causal_mask', 'transformer.h.31.attn.causal_mask', 'transformer.h.4.attn.causal_mask', 'transformer.h.5.attn.causal_mask', 'transformer.h.6.attn.causal_mask', 'transformer.h.7.attn.causal_mask', 'transformer.h.8.attn.causal_mask', 'transformer.h.9.attn.causal_mask']\n",
      "- This IS expected if you are initializing CodeGenForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CodeGenForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "base_model_name = \"salesforce/CodeGen2-7B\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name)\n",
    "adapter_path = \"./qlora-text-to-sql-final\"  # This is the folder with LoRA weights\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "lora_model = lora_model.merge_and_unload()\n",
    "\n",
    "lora_model.save_pretrained(\"./merged-full-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9c87c9d-2293-40ff-bccc-30febcd95d21",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 1: Find the total number of students enrolled in the 'Computer Science' department.\n",
      "Generated SQL:\n",
      " Question: Find the total number of students enrolled in the 'Computer Science' department.\n",
      "Generate the SQL query:\n",
      "SELECT COUNT(id) AS total FROM Students WHERE department = 'Computer Science'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test 2: Retrieve the names of employees who have a salary greater than 100,000 and work in the 'Engineering' department.\n",
      "Generated SQL:\n",
      " Question: Retrieve the names of employees who have a salary greater than 100,000 and work in the 'Engineering' department.\n",
      "Generate the SQL query:\n",
      "SELECT Employee_Name FROM Employees WHERE  (Employees.Salary>= 100000) AND (Employees.Department LIKE '% Engineering' )\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test 3: List the top 5 customers who have made the highest total purchases in the last year.\n",
      "Generated SQL:\n",
      " Question: List the top 5 customers who have made the highest total purchases in the last year.\n",
      "Generate the SQL query:\n",
      "SELECT Customers.id, Customers.name, Customers.id, Customers.  year, Orders.id FROM Customers JOIN Orders ON Customers.id = Orders.id Customers_id Customers.  year Orders.id FROM Customers JOIN Orders ON Customers.id = Orders.id Customers_id Customers.  year Orders.id FROM Customers JOIN Orders ON Customers.id = Orders.id Customers_id Customers.  year Orders.id FROM Customers JOIN Orders ON Customers.id = Orders.id Customers_id Customers.  year Orders.id FROM Customers JOIN Orders ON Customers.id = Orders.id Customers_\n",
      "================================================================================\n",
      "\n",
      "Test 4: Find the total sales revenue for each product category in the last 6 months.\n",
      "Generated SQL:\n",
      " Question: Find the total sales revenue for each product category in the last 6 months.\n",
      "Generate the SQL query:\n",
      "SELECT products.category_id AS 'category_id', products.category_name AS 'category_name',\n",
      "products.revenue AS 'revenue'\n",
      "FROM Products\n",
      "INNER JOIN Categories ON Products.category_id = Categories.category_id\n",
      "WHERE Products.created_at BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 6 MONTH)\n",
      "AND DATE_SUB(CURRENT_DATE(), INTERVAL 1 MONTH)\n",
      "ORDER BY category_name ASC;\n",
      "================================================================================\n",
      "\n",
      "Test 5: Retrieve the student names and their average grades for courses where the grade is above 85.\n",
      "Generated SQL:\n",
      " Question: Retrieve the student names and their average grades for courses where the grade is above 85.\n",
      "Generate the SQL query:\n",
      "SELECT student_name, avg(grade) FROM AS_grade WHERE grade>85 GROUP BY student_name\n",
      "================================================================================\n",
      "\n",
      "Test 6: Find all employees who have worked for the company for more than 5 years and have at least one promotion.\n",
      "Generated SQL:\n",
      " Question: Find all employees who have worked for the company for more than 5 years and have at least one promotion.\n",
      "Generate the SQL query:\n",
      "SELECT employees.id ,employees.first_name ,employees.last_name ,employees.id ,employees.employee_name ,employees.manager_id ,employees.manager_name  FROM employees JOIN employees AS employees_2 ON employees.manager_id = employees_2.id JOIN employees AS employees_3 ON employees_2.id = employees_3.id WHERE employees.manager_id IN( SELECT employees_4.id FROM employees AS employees_4 JOIN employees AS employees_5 ON employees_4.manager_id = employees_5.id\n",
      "================================================================================\n",
      "\n",
      "Test 7: List all orders that were placed in the last month and are still pending delivery.\n",
      "Generated SQL:\n",
      " Question: List all orders that were placed in the last month and are still pending delivery.\n",
      "Generate the SQL query:\n",
      "SELECT_ORDERS_WHERE_DATE_ = SELECT  ORDERS WHERE DATE_ BETWEEN CURRENT_DATE() - INTERVAL 1 MONTH - INTERVAL 1 DAY AND CURRENT_DATE() - INTERVAL 1 DAY\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test 8: Get the names of customers who have never placed an order.\n",
      "Generated SQL:\n",
      " Question: Get the names of customers who have never placed an order.\n",
      "Generate the SQL query:\n",
      "SELECT orders.cust_name\n",
      "FROM orders\n",
      "WHERE orders.customer_id NOT IN( SELECT customers.customer_id FROM customers)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test 9: Find the number of distinct suppliers for each product in the inventory.\n",
      "Generated SQL:\n",
      " Question: Find the number of distinct suppliers for each product in the inventory.\n",
      "Generate the SQL query:\n",
      "SELECT Products.id AS product_id, Products.product AS product_name, Products.supplier AS supplier_id, Supplier.supplier AS supplier_name, Supplier.id AS supplier_id FROM Products JOIN Supplier ON Products.supplier = Supplier.id\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test 10: Retrieve all flight details for flights scheduled between 6 AM and 12 PM tomorrow.\n",
      "Generated SQL:\n",
      " Question: Retrieve all flight details for flights scheduled between 6 AM and 12 PM tomorrow.\n",
      "Generate the SQL query:\n",
      "SELECT_FLIGHTS WHERE  FROM Flight T WHERE T.TUESDAY_TIME BETWEEN '00:00:00' AND '12:00:00' AND  T.TUESDAY_DATE BETWEEN 'TUESDAY_DATE BETWEEN TUESDAY_DATE AND 'TUESDAY_DATE' AND  T.TUESDAY_TIME BETWEEN 'TUESDAY_TIME' AND 'TUESDAY_TIME' AND  T.TUESDAY_TIME BETWEEN 'TUESDAY_TIME' AND 'TUESDAY_TIME'\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    \"Find the total number of students enrolled in the 'Computer Science' department.\",\n",
    "    \"Retrieve the names of employees who have a salary greater than 100,000 and work in the 'Engineering' department.\",\n",
    "    \"List the top 5 customers who have made the highest total purchases in the last year.\",\n",
    "    \"Find the total sales revenue for each product category in the last 6 months.\",\n",
    "    \"Retrieve the student names and their average grades for courses where the grade is above 85.\",\n",
    "    \"Find all employees who have worked for the company for more than 5 years and have at least one promotion.\",\n",
    "    \"List all orders that were placed in the last month and are still pending delivery.\",\n",
    "    \"Get the names of customers who have never placed an order.\",\n",
    "    \"Find the number of distinct suppliers for each product in the inventory.\",\n",
    "    \"Retrieve all flight details for flights scheduled between 6 AM and 12 PM tomorrow.\"\n",
    "]\n",
    "\n",
    "for idx, question in enumerate(test_questions, 1):\n",
    "    generated_sql = generate_sql(question)\n",
    "    print(f\"\\nTest {idx}: {question}\")\n",
    "    print(\"Generated SQL:\\n\", generated_sql)\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd7cd9a-566f-4269-b790-0be6012121ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
